{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 \u2014 Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q kaggle \"tensorflow>=2.17.0\" gradio matplotlib\n",
        "\n",
        "# Python imports\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 \u2014 Kaggle Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload kaggle.json API key\n",
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json\n",
        "\n",
        "# Set up Kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset if not already present\n",
        "if not os.path.exists(\"/content/new-plant-diseases-dataset\"):\n",
        "    !kaggle datasets download -d vipoooool/new-plant-diseases-dataset -p /content\n",
        "    !unzip -q /content/new-plant-diseases-dataset.zip -d /content/new-plant-diseases-dataset\n",
        "\n",
        "!ls -lah /content/new-plant-diseases-dataset | sed -n '1,200p'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 \u2014 Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "N_LAST_LAYERS = 10   # Unfreeze last 10 layers for fine-tuning\n",
        "SEED = 1337\n",
        "NUM_CLASSES = 38\n",
        "\n",
        "train_dir = \"/content/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
        "valid_dir = \"/content/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
        "\n",
        "# Verify paths\n",
        "for p in [train_dir, valid_dir]:\n",
        "    if not os.path.exists(p):\n",
        "        print(f\"ERROR: path not found: {p}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "print(\"train_dir:\", train_dir)\n",
        "print(\"valid_dir:\", valid_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 \u2014 Data Exploration & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def show_sample_images(base_path, num_classes=5, images_per_class=3):\n",
        "    \"\"\"Display random sample images from the dataset\"\"\"\n",
        "    class_names = os.listdir(base_path)\n",
        "    random_classes = random.sample(class_names, min(num_classes, len(class_names)))\n",
        "\n",
        "    fig, axes = plt.subplots(num_classes, images_per_class, figsize=(12, 3*num_classes))\n",
        "    fig.suptitle('Sample Images from Dataset', fontsize=16)\n",
        "\n",
        "    for i, class_name in enumerate(random_classes):\n",
        "        class_path = os.path.join(base_path, class_name)\n",
        "        images = os.listdir(class_path)\n",
        "        random_images = random.sample(images, min(images_per_class, len(images)))\n",
        "\n",
        "        for j, img_name in enumerate(random_images):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = plt.imread(img_path)\n",
        "            axes[i, j].imshow(img)\n",
        "            axes[i, j].axis('off')\n",
        "            if j == 0:\n",
        "                axes[i, j].set_title(class_name.replace('___', '\\n'), fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(train_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 \u2014 Dataset Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images(directory):\n",
        "    \"\"\"Count total images and images per class\"\"\"\n",
        "    total_images = 0\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            num_images = len(os.listdir(class_path))\n",
        "            class_counts[class_name] = num_images\n",
        "            total_images += num_images\n",
        "    return total_images, class_counts\n",
        "\n",
        "train_total, train_counts = count_images(train_dir)\n",
        "valid_total, valid_counts = count_images(valid_dir)\n",
        "\n",
        "print(f\"Training images: {train_total}\")\n",
        "print(f\"Validation images: {valid_total}\")\n",
        "print(f\"Number of classes: {len(train_counts)}\")\n",
        "print(f\"\\nClass distribution (first 10):\")\n",
        "for i, (class_name, count) in enumerate(list(train_counts.items())[:10]):\n",
        "    print(f\"  {class_name}: {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.6 \u2014 Data Generators (Preprocessing & Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Training generator with LIGHT augmentation (dataset already augmented)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode='reflect'\n",
        ")\n",
        "\n",
        "# Validation generator \u2014 NO augmentation\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "valid_gen = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.7 \u2014 Load Pre-trained MobileNetV2 & Configure Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Load pretrained MobileNetV2 backbone\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "print(\"MobileNetV2 loaded successfully!\")\n",
        "print(f\"Total layers in base model: {len(base_model.layers)}\")\n",
        "\n",
        "# Freeze all layers initially\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Unfreeze last N layers for fine-tuning\n",
        "if N_LAST_LAYERS > 0:\n",
        "    for layer in base_model.layers[-N_LAST_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "# Count parameters\n",
        "trainable_count = sum([tf.size(w).numpy() for w in base_model.trainable_weights])\n",
        "non_trainable_count = sum([tf.size(w).numpy() for w in base_model.non_trainable_weights])\n",
        "\n",
        "print(f\"Trainable parameters: {trainable_count:,}\")\n",
        "print(f\"Non-trainable parameters: {non_trainable_count:,}\")\n",
        "print(f\"Unfrozen last {N_LAST_LAYERS} layers for fine-tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.8 \u2014 Build Complete Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the complete model\n",
        "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
        "x = base_model(inputs, training=False)  # Frozen BatchNorm layers\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.35)(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name=\"mobilenetv2_plant_disease_classifier\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.9 \u2014 Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),  # Low LR for fine-tuning\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model compiled successfully!\")\n",
        "print(\"Optimizer: Adam (lr=1e-4)\")\n",
        "print(\"Loss function: Categorical Crossentropy\")\n",
        "print(\"Metrics: Accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.10 \u2014 Setup Training Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    # Save best model based on validation accuracy\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"/content/mobilenetv2_best.keras\",\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Reduce learning rate when validation loss plateaus\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Stop training if no improvement\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=6,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"Callbacks configured:\")\n",
        "print(\"  1. ModelCheckpoint - Saves best model\")\n",
        "print(\"  2. ReduceLROnPlateau - Adjusts learning rate\")\n",
        "print(\"  3. EarlyStopping - Prevents overfitting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.11 \u2014 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_gen,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.12 \u2014 Visualize Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history.get('accuracy', []), label='train_accuracy')\n",
        "plt.plot(history.history.get('val_accuracy', []), label='val_accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history.get('loss', []), label='train_loss')\n",
        "plt.plot(history.history.get('val_loss', []), label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.13 \u2014 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_loss, val_acc = model.evaluate(valid_gen)\n",
        "print(f\"Validation loss: {val_loss:.4f}, accuracy: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.14 \u2014 Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_path = \"/content/mobilenetv2_final.keras\"\n",
        "model.save(final_path)\n",
        "print(\"Saved final model to:\", final_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.15 \u2014 Save Class Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "print(f\"Total classes: {len(class_names)}\")\n",
        "print(\"First 5 classes:\", class_names[:5])\n",
        "\n",
        "# Save class names to JSON\n",
        "with open('/content/class_names.json', 'w') as f:\n",
        "    json.dump(class_names, f)\n",
        "print(\"Class names saved to class_names.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "plant_disease_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}